{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQXG0Bejxu9L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import optuna\n",
        "import shap\n",
        "import mlflow\n",
        "import altair as alt\n",
        "import uvicorn\n",
        "import dvc.api\n",
        "import streamlit as st\n",
        "from fastapi import FastAPI\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import GradientBoostingRegressor, StackingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import pandera as pa\n",
        "from pandera.typing import DataFrame\n",
        "from evidently.report import Report\n",
        "from evidently.metric_preset import DataDriftPreset\n",
        "from google.colab import drive\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "import nest_asyncio\n",
        "from sdv.tabular import GaussianCopula\n",
        "\n",
        "# Configuración de MLFlow\n",
        "mlflow.set_tracking_uri(\"mlruns\")\n",
        "mlflow.set_experiment(\"salary_prediction\")\n",
        "\n",
        "# Configuración de rutas y carga de datos\n",
        "def load_and_validate_data():\n",
        "    df = pl.read_csv(\"salaries_clean.csv\").to_pandas()\n",
        "    df = df.rename(columns={\n",
        "        \"Age\": \"age\",\n",
        "        \"Gender\": \"gender\",\n",
        "        \"Education Level\": \"education_level\",\n",
        "        \"Job Title\": \"job_title\",\n",
        "        \"Years of Experience\": \"years_experience\",\n",
        "        \"Salary\": \"salary\"\n",
        "    })\n",
        "    df[\"age\"] = df[\"age\"].astype(\"int64\")\n",
        "    df[\"years_experience\"] = df[\"years_experience\"].astype(\"int64\")\n",
        "    return df\n",
        "\n",
        "# Generación de Datos Sintéticos\n",
        "def generate_synthetic_data(output_path=\"synthetic_salaries.csv\", num_samples=1000):\n",
        "    df = load_and_validate_data()\n",
        "    model = GaussianCopula()\n",
        "    model.fit(df)\n",
        "    synthetic_data = model.sample(num_samples)\n",
        "    synthetic_data.to_csv(output_path, index=False)\n",
        "    return synthetic_data\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "def preprocess_data(df):\n",
        "    X = df[['age', 'gender', 'education_level', 'job_title', 'years_experience']]\n",
        "    y = df['salary']\n",
        "    preprocessor = ColumnTransformer([\n",
        "        (\"num\", StandardScaler(), ['age', 'years_experience']),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), ['gender', 'education_level', 'job_title'])\n",
        "    ])\n",
        "    X_transformed = preprocessor.fit_transform(X)\n",
        "    return train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Entrenamiento de modelos con MLFlow\n",
        "def train_and_compare_models():\n",
        "    df = load_and_validate_data()\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(df)\n",
        "\n",
        "    models = {\n",
        "        \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.1),\n",
        "        \"XGBoost\": XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42, n_jobs=-1),\n",
        "        \"LightGBM\": LGBMRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42, n_jobs=-1),\n",
        "        \"Neural Network\": MLPRegressor(hidden_layer_sizes=(50, 25), max_iter=300, random_state=42)\n",
        "    }\n",
        "\n",
        "    best_model = None\n",
        "    best_score = float('-inf')\n",
        "\n",
        "    with mlflow.start_run():\n",
        "        with ThreadPoolExecutor() as executor:\n",
        "            futures = {executor.submit(lambda m: cross_val_score(m, X_train, y_train, scoring=\"r2\", cv=3).mean(), model): name for name, model in models.items()}\n",
        "            for future in futures:\n",
        "                score = future.result()\n",
        "                mlflow.log_metric(f\"R2_{futures[future]}\", score)\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_model = models[futures[future]]\n",
        "\n",
        "    best_model.fit(X_train, y_train)\n",
        "    joblib.dump(best_model, \"salary_model.pkl\")\n",
        "    mlflow.sklearn.log_model(best_model, \"best_model\")\n",
        "    return best_model, X_test, y_test\n",
        "\n",
        "# API con FastAPI y guardado en SQL\n",
        "app = FastAPI()\n",
        "model, X_test, y_test = train_and_compare_models()\n",
        "\n",
        "@app.post(\"/predict/\")\n",
        "def predict_salary(age: int, gender: str, education_level: str, job_title: str, years_experience: int):\n",
        "    X_input = np.asarray([[age, gender, education_level, job_title, years_experience]])\n",
        "    predicted_salary = model.predict(X_input)[0]\n",
        "\n",
        "    conn = sqlite3.connect(\"salaries.db\")\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS salary_predictions (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            age INTEGER,\n",
        "            gender TEXT,\n",
        "            education_level TEXT,\n",
        "            job_title TEXT,\n",
        "            years_experience INTEGER,\n",
        "            predicted_salary REAL\n",
        "        )\n",
        "    ''')\n",
        "    cursor.execute('''\n",
        "        INSERT INTO salary_predictions (age, gender, education_level, job_title, years_experience, predicted_salary)\n",
        "        VALUES (?, ?, ?, ?, ?, ?)\n",
        "    ''', (age, gender, education_level, job_title, years_experience, predicted_salary))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    return {\"predicted_salary\": round(predicted_salary, 2)}\n",
        "\n",
        "# Visualización con Altair\n",
        "def visualize_data(df):\n",
        "    chart = alt.Chart(df).mark_circle(size=60).encode(\n",
        "        alt.X(\"years_experience:Q\", title=\"Años de Experiencia\"),\n",
        "        alt.Y(\"salary:Q\", title=\"Salario\"),\n",
        "        alt.Color(\"education_level:N\", title=\"Nivel Educativo\"),\n",
        "        tooltip=[\"years_experience\", \"salary\", \"education_level\"]\n",
        "    ).interactive()\n",
        "    chart.save(\"salary_scatter.html\")\n",
        "\n",
        "# Iniciar el servidor\n",
        "if __name__ == \"__main__\":\n",
        "    nest_asyncio.apply()\n",
        "    uvicorn.run(app, host=\"127.0.0.1\", port=8000, workers=1)\n"
      ]
    }
  ]
}